import streamlit as st
import cv2
import numpy as np
import pytesseract
import json
from fuzzywuzzy import process
from PIL import Image

st.set_page_config(page_title="NMS Inventory Analyzer", page_icon="üöÄ")

@st.cache_data
def load_db():
    try:
        with open('nms_items.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def process_image(pil_image):
    # 1. Konwersja PIL -> OpenCV
    img_array = np.array(pil_image)
    if len(img_array.shape) == 3:
        img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    else:
        img = img_array

    # 2. POWIƒòKSZENIE (Upscaling) - Kluczowe dla ma≈Çych napis√≥w
    # Powiƒôkszamy obraz 2-krotnie, u≈ºywajƒÖc interpolacji sze≈õciennej
    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)

    # 3. Konwersja na szaro≈õƒá
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 4. Odszumianie (Lekki Blur)
    # Usuwa "ziarno" ze zdjƒôcia zrobionego telefonem/screena
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    # 5. ADAPTIVE THRESHOLDING (To jest game changer)
    # Zamiast sztywnego progu, algorytm bada sƒÖsiedztwo pikseli.
    # Sprawia, ≈ºe bia≈Çy tekst na ciemnym tle staje siƒô czarnym tekstem na bia≈Çym tle.
    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY, 31, 2)

    # 6. OCR
    # psm 11 (sparse text) lub psm 3 (auto segmentation)
    # Dodajemy whitelist (opcjonalnie), ≈ºeby szuka≈Ç tylko liter A-Z
    custom_config = r'--psm 11'
    text = pytesseract.image_to_string(thresh, config=custom_config)
    
    return text, thresh # Zwracamy te≈º obrazek 'thresh' do podglƒÖdu

def analyze_text(raw_text, db):
    results = []
    # Filtrujemy bardzo kr√≥tkie ≈õmieci (mniej ni≈º 4 znaki)
    lines = [line.strip() for line in raw_text.split('\n') if len(line) > 3]
    db_keys = list(db.keys())
    
    for line in lines:
        # Usuwamy znaki specjalne, kt√≥re OCR czƒôsto dodaje (np. | [ ] { })
        clean_line = ''.join(e for e in line if e.isalnum() or e.isspace())
        
        match, score = process.extractOne(clean_line.upper(), db_keys)
        
        # Je≈õli wynik jest wysoki, dodajemy
        if score >= 70: # Lekko obni≈ºony pr√≥g dla trudnych screen√≥w
            item_data = db[match]
            if not any(d['Przedmiot'] == match for d in results):
                results.append({
                    "Przedmiot": match,
                    "Akcja": item_data['action'],
                    "Typ": item_data['type'],
                    "Rada": item_data['tip'],
                    "Orygina≈Ç": line # Debug: co zobaczy≈Ç OCR
                })
    return results

# --- FRONTEND ---

st.title("üöÄ NMS Inventory Analyzer v2")
st.write("Wgraj screen z PS App.")

uploaded_file = st.file_uploader("Wybierz zdjƒôcie...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Orygina≈Ç', use_column_width=True)
    
    st.write("‚öôÔ∏è Przetwarzam obraz...")
    
    database = load_db()
    
    # Pobieramy tekst ORAZ przetworzony obraz
    raw_text, processed_img = process_image(image)
    
    # --- DEBUG VIEW ---
    with st.expander("üëÅÔ∏è Zobacz jak komputer widzi Tw√≥j screen (Debug)"):
        st.write("Je≈õli tutaj nie widzisz wyra≈∫nych czarnych liter, OCR te≈º ich nie zobaczy.")
        st.image(processed_img, caption='Obraz po filtrach', use_column_width=True)
        st.text("Surowy tekst:")
        st.text(raw_text)
    # ------------------

    found_items = analyze_text(raw_text, database)
    
    if found_items:
        st.success(f"Znaleziono {len(found_items)} przedmiot√≥w!")
        for item in found_items:
            color = "green" if item['Akcja'] == "TRZYMAJ" else "red"
            if "SPRZEDAJ" in item['Akcja']: color = "orange"
            
            with st.container():
                st.markdown(f"### :{color}[{item['Akcja']}] {item['Przedmiot']}")
                st.caption(f"Typ: {item['Typ']} (Dopasowano z: '{item['Orygina≈Ç']}')")
                st.info(item['Rada'])
                st.divider()
    else:
        st.error("Nie znaleziono przedmiot√≥w.")
        st.info("Sp√≥jrz w sekcjƒô 'Debug' powy≈ºej. Je≈õli tekst na czarno-bia≈Çym zdjƒôciu jest zamazany, spr√≥buj zrobiƒá screena bli≈ºej lub z innej zak≈Çadki ekwipunku.")
